{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Credit Risk Classification\n\nIn this notebook, we perform a step-by-step analysis using logistic regression to predict loan status. We:\n- Read and inspect the lending data\n- Create features (X) and labels (y)\n- Split the data into training and test sets\n- Train a logistic regression model\n- Evaluate the model with a confusion matrix and classification report"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": false}, "source": "# Importing necessary libraries\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nprint('Imported necessary libraries.')"}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 1: Load and Inspect Data\n\nRead the CSV file and check the first few rows of the data to understand its structure."}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": false}, "source": "# Load the lending data into a DataFrame\ntry:\n    df = pd.read_csv('lending_data.csv', encoding='ascii')\n    print('Data loaded successfully.')\n    print('Data preview:')\n    print(df.head())\nexcept Exception as e:\n    print('Error loading data:', e)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 2: Create Features and Labels\n\n- Create labels set `y` from the `loan_status` column.\n- Create features DataFrame `X` by dropping the `loan_status` column."}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": false}, "source": "# Create labels (y) and features (X)\ntry:\n    y = df['loan_status']\n    X = df.drop('loan_status', axis=1)\n    print('Labels and features created.')\n    print('Labels (first 5):')\n    print(y.head())\n    print('Features (first 5):')\n    print(X.head())\nexcept Exception as e:\n    print('Error processing features and labels:', e)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 3: Split Data into Training and Testing Sets\n\nWe use a 70/30 split to create training and testing sets."}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": false}, "source": "# Split data into training and testing sets\ntry:\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n    print('Data successfully split into training and testing sets.')\n    print('Training set size:', X_train.shape)\n    print('Testing set size:', X_test.shape)\nexcept Exception as e:\n    print('Error splitting the data:', e)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 4: Train a Logistic Regression Model\n\nWe create an instance of LogisticRegression, train it on the training set, and then predict using the testing set."}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": false}, "source": "# Initialize and train the logistic regression model\ntry:\n    model = LogisticRegression(max_iter=1000)  # increased iterations for convergence\n    model.fit(X_train, y_train)\n    print('Model training completed.')\nexcept Exception as e:\n    print('Error training the model:', e)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Step 5: Model Predictions and Evaluation\n\n- Predict the test data labels using the trained model\n- Generate a confusion matrix and classification report"}, {"cell_type": "code", "execution_count": null, "metadata": {"trusted": false}, "source": "# Generate predictions on the test dataset\ntry:\n    y_pred = model.predict(X_test)\n    print('Predictions generated.')\n\n    # Evaluating Model\n    cm = confusion_matrix(y_test, y_pred)\n    cr = classification_report(y_test, y_pred)\n    print('Confusion Matrix:')\n    print(cm)\n    print('\\nClassification Report:')\n    print(cr)\nexcept Exception as e:\n    print('Error in model prediction or evaluation:', e)"}, {"cell_type": "markdown", "metadata": {}, "source": "## Conclusion\n\nThe logistic regression model has been trained and evaluated. Review the confusion matrix and classification report to understand its performance on predicting healthy (0) versus high-risk (1) loans.\n\n*Note: Debug print statements have been included throughout the notebook to help track the process.*"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.8.5"}}, "nbformat": 4, "nbformat_minor": 4}